<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>curriculum on JimBobBennett</title><link>https://jimbobbennett.dev</link><description>Recent content in curriculum on JimBobBennett</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><managingEditor>jim@jimbobbennett.io (Jim Bennett)</managingEditor><webMaster>jim@jimbobbennett.io (Jim Bennett)</webMaster><lastBuildDate>Fri, 09 Jul 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://jimbobbennett.dev/tags/curriculum/index.xml" rel="self" type="application/rss+xml"/><item><title>Led Ticker Tape</title><link>https://jimbobbennett.dev/blogs/led-ticker-tape/</link><pubDate>Fri, 25 Feb 2022 17:01:05 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/led-ticker-tape/</guid><description>&lt;p>&lt;img src="hello-lights.png" alt="An LED panel showing Hello in green">&lt;/p>
&lt;p>Anyone who knows me knows I&amp;rsquo;m a big fan of IoT and LEDs. I love using IoT devices to control lights, from the LEDs behind my desk to &lt;a href="https://www.youtube.com/watch?v=h5ETn4PTdQA">smart pumpkins&lt;/a>!&lt;/p>
&lt;p>I&amp;rsquo;ve been giving the .NET IoT libraries a spin for an upcoming project using a Raspberry Pi Zero W 2. I&amp;rsquo;m usually a Python person when using a Pi, but the project I&amp;rsquo;m working on needs a service that doesn&amp;rsquo;t have Python libraries that run on a Pi. Instead it has a .NET library, so it was time to break out my C# skills for the first time in years.&lt;/p>
&lt;p>I wanted to build an LED panel that can display text, either static text or scrolling text. So I picked up this &lt;a href="https://amzn.to/3sVjF7M">WS2812B panel from Amazon (affiliate link)&lt;/a>, and started to dig into the .NET IoT libraries. WS2818b LEDs are also known as NeoPixels, and are addressable multicolor LEDs, so you can light up individual ones in any color you like. They are addressed based on the order they are connected to your device, so the first pixel in a string of LEDs is 0, the next is 1 and so on. You can add as many as you like, and the addresses just keep going up.&lt;/p>
&lt;p>The .NET IoT libraries are on GitHub at &lt;a href="https://github.com/dotnet/iot">github.com/dotnet/iot&lt;/a> and available as a NuGet. They support a wide range of boards including the Raspberry Pi.&lt;/p>
&lt;h2 id="lighting-leds-in-c">Lighting LEDs in C#&lt;/h2>
&lt;p>I started as I usually do with a clean install of Raspberry Pi OS Lite. I use the Lite version as I access my Pi remotely using VS Code for all my development. You can read more on how I do this on &lt;a href="https://www.raspberrypi.com/news/coding-on-raspberry-pi-remotely-with-visual-studio-code/">my blog post on the Raspberry Pi blog&lt;/a>. When I connected to my Pi I installed .NET 6, and the C# extension in VS Code.&lt;/p>
&lt;blockquote>
&lt;p>One thing to note for the C# extension is it doesn&amp;rsquo;t support remote debugging on the Pi Zero W 2.&lt;/p>
&lt;/blockquote>
&lt;p>The .NET IoT libraries have a small amount of documentation and samples, so it wasn&amp;rsquo;t too much effort to get the LEDs lighting up.&lt;/p>
&lt;p>The .NET libraries control these pixels over SPI, so they need to be connected to an SPI pin and ground on the Pi, as well as to a 5V power supply. You can&amp;rsquo;t use the 5V pins on the Pi as the panel can draw too much power and burn your Pi out, it&amp;rsquo;s best to use an external 5V power supply, either from a USB connection or a power converter plugged into the mains.&lt;/p>
&lt;p>You also need to do a bit of SPI configuration, and this is documented in the &lt;a href="https://github.com/dotnet/iot/tree/main/src/devices/Ws28xx">GitHub source code for the WS2812B device code&lt;/a>.&lt;/p>
&lt;blockquote>
&lt;p>This is different to using the Adafruit NeoPixel libraries from Python, where you use different pins and don&amp;rsquo;t need any SPI configuration.&lt;/p>
&lt;/blockquote>
&lt;p>To use the .NET libraries, you start by creating an SPI configuration, then use that to create the pixels:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-csharp" data-lang="csharp">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">// Create connection settings to connect to the panel using SPI&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>SpiConnectionSettings settings = &lt;span style="color:#66d9ef">new&lt;/span>(&lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ClockFrequency = &lt;span style="color:#ae81ff">2_400_000&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Mode = SpiMode.Mode0,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> DataBitLength = &lt;span style="color:#ae81ff">8&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>};
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">// Create an SPI device&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">var&lt;/span> spi = SpiDevice.Create(settings);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">// Use the SPI device to connect to the LEDs&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">// and pass the number of LEDs&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">var&lt;/span> neoPixels = &lt;span style="color:#66d9ef">new&lt;/span> Ws2812b(spi, &lt;span style="color:#ae81ff">256&lt;/span>);
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>When you create the pixels, you pass in the length of the strip. I&amp;rsquo;ve been using a 8x32 panel, which is actually a 256 pixel long strip arranged in and up/down pattern.&lt;/p>
&lt;p>Once created, you light pixels by getting a &lt;code>BitmapImage&lt;/code> from them, and setting colors on that. This image is a &lt;code>length x 1&lt;/code> image, so 1 pixel tall, and as wide as the length of the LEDs. For example, my 8x32 panel is 256 pixels long, so is a bitmap of 256x1.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-csharp" data-lang="csharp">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">var&lt;/span> img = neoPixels.Image;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>You can then set pixels in this image to the color you want. The color is set using the &lt;code>System.Drawing.Color&lt;/code> struct, which wraps ARGB values. The A (alpha channel) is ignored, so you set pixel brightness by reducing the value of the R, G, and B.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-csharp" data-lang="csharp">&lt;span style="display:flex;">&lt;span>img.SetPixel(&lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, Color.Red);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>img.SetPixel(&lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, Color.Green);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>img.SetPixel(&lt;span style="color:#ae81ff">2&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, Color.Blue);
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Once the pixels are set in the image, it is committed and the LEDs updated.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-csharp" data-lang="csharp">&lt;span style="display:flex;">&lt;span>neoPixels.Update();
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>One quirk of the bitmaps, is you have to set all the pixels up to the last one you want set. So if you want to set pixel 10 to be red, you have to also set pixels 0-9 to something, even if it is &lt;code>Color.Black&lt;/code> (off). The first pixel you set is mapped to the first LED in the strip, so if you just set pixels 10-20, then the strip is set as if the first LED was pixel 10.&lt;/p>
&lt;p>For example, if you just want to set pixel 2 to blue, you can&amp;rsquo;t do this:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-csharp" data-lang="csharp">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">var&lt;/span> img = neoPixels.Image;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>img.SetPixel(&lt;span style="color:#ae81ff">2&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, Color.Blue);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>neoPixels.Update();
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>What will happen here is pixel 2 is the first one with a value, so that will be considered the first pixel in the strip, so the first LED will light up blue.
What you need to do is:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-csharp" data-lang="csharp">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">var&lt;/span> img = neoPixels.Image;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>img.SetPixel(&lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, Color.Black);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>img.SetPixel(&lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, Color.Black);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>img.SetPixel(&lt;span style="color:#ae81ff">2&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, Color.Blue);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>neoPixels.Update();
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This will set the pixels 0 and 1 to off, and pixel 2 to blue.&lt;/p>
&lt;h2 id="writing-text">Writing text&lt;/h2>
&lt;p>I wanted to make my panel show text, either short static text, or scrolling text. The first thing I needed was a font - something that defines how to create letters from pixels. I found a similar project based on Arduino in a &lt;a href="https://github.com/bigjosh/SimpleTickerTape/tree/main/fonts">GitHub project from Josh Levine&lt;/a> so leveraged this code for a font and re-wrote it in C#.&lt;/p>
&lt;p>Next I needed the mapping code. These fonts are defined as columns of binary data, so the bits to set. Each character is 8 bits tall (the size of my panel), and 6 bits wide. This mapping code was a bit of fun as I not only needed to divide up my pixels into columns, and map from a pixel in the 1 dimensional strip to a character pixel, but the strips go up and down!&lt;/p>
&lt;p>The way this panel is made is by weaving an LED strip up and down, so the pixels start at 0 on the top left, go down to 7 on the left-most column, then across one pixel to the right to 8, then up to 15.&lt;/p>
&lt;p>This gives for the first few columns:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">0&lt;/span> &lt;span style="color:#ae81ff">15&lt;/span> &lt;span style="color:#ae81ff">16&lt;/span> &lt;span style="color:#ae81ff">31&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">1&lt;/span> &lt;span style="color:#ae81ff">14&lt;/span> &lt;span style="color:#ae81ff">17&lt;/span> &lt;span style="color:#ae81ff">30&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">2&lt;/span> &lt;span style="color:#ae81ff">13&lt;/span> &lt;span style="color:#ae81ff">18&lt;/span> &lt;span style="color:#ae81ff">29&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">3&lt;/span> &lt;span style="color:#ae81ff">12&lt;/span> &lt;span style="color:#ae81ff">19&lt;/span> &lt;span style="color:#ae81ff">28&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">4&lt;/span> &lt;span style="color:#ae81ff">11&lt;/span> &lt;span style="color:#ae81ff">20&lt;/span> &lt;span style="color:#ae81ff">27&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">5&lt;/span> &lt;span style="color:#ae81ff">10&lt;/span> &lt;span style="color:#ae81ff">21&lt;/span> &lt;span style="color:#ae81ff">26&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">6&lt;/span> &lt;span style="color:#ae81ff">9&lt;/span> &lt;span style="color:#ae81ff">22&lt;/span> &lt;span style="color:#ae81ff">25&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">7&lt;/span> &lt;span style="color:#ae81ff">8&lt;/span> &lt;span style="color:#ae81ff">23&lt;/span> &lt;span style="color:#ae81ff">24&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This means that the mapping code needs to alternate - for 0dd numbered columns the pixels go down, for even numbered the pixels go up so the mapping has to be reversed!&lt;/p>
&lt;p>I&amp;rsquo;m not going to dive into all this mapping here, but you can find the code with full documentation in my &lt;a href="https://github.com/jimbobbennett/NeoPixelTickerTape">NeoPixelTickerTape GitHub repo&lt;/a>.&lt;/p>
&lt;p>I then added scrolling code that writes text starting at the right-most column, then re-writes it shifting left a column at a time.&lt;/p>
&lt;p>&lt;img src="tickertape.gif" alt="Hello world scrolling across the ticker tape">&lt;/p>
&lt;h2 id="check-out-the-code">Check out the code&lt;/h2>
&lt;p>You can find the code with full documentation in my &lt;a href="https://github.com/jimbobbennett/NeoPixelTickerTape">NeoPixelTickerTape GitHub repo&lt;/a>.&lt;/p>
&lt;p>You can also download a NuGet package to use in your apps:&lt;/p>
&lt;p>&lt;img src="https://img.shields.io/nuget/v/JimBobBennett.NeoPixelTickerTape.svg?style=flat&amp;amp;logo=nuget" alt="Select this to access the nuget">&lt;/p></description></item><item><title>Auto-posting to dev.to using a GitHub action</title><link>https://jimbobbennett.dev/blogs/auto-posting-to-dev-to/</link><pubDate>Thu, 03 Feb 2022 00:00:00 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/auto-posting-to-dev-to/</guid><description>&lt;p>&lt;img src="stream-screenshot.png" alt="A screenshot from teh live stream mentioned here">&lt;/p>
&lt;p>I&amp;rsquo;ve been wanting to build a tool to post markdown automatically to blogging platforms. That way I (or anyone else) can write a blog post in markdown, save it in a &lt;a href="https://github.com">GitHub&lt;/a> repo, and have it automatically posted to a blogging platform of their choice.&lt;/p>
&lt;p>I&amp;rsquo;ve created a small Python app to do this, and you can find it on GitHub at &lt;a href="https://github.com/jimbobbennett/auto-blog-poster">github.com/jimbobbennett/auto-blog-poster&lt;/a>. You add some special folders to any folders containing README.md files, and it will create a blog post from the markdown. It will also track when the README file changes and update the blog post.&lt;/p>
&lt;p>It&amp;rsquo;s slightly annoying to have to remember to run this every time you create or update a post, so I wanted to make it so it could be run automatically. GitHub actions are the perfect way to do this.&lt;/p>
&lt;h2 id="what-are-github-actions">What are GitHub actions?&lt;/h2>
&lt;p>GitHub actions is GitHubs CI/CD solution. CI is continuous integration, meaning every time code changes, your code can be built and tested. CD is continuous deployment, so once code is tested it can be deployed automatically.&lt;/p>
&lt;p>Essentially you can specify code that is run whenever someone checks in any changes, merges a branch or PR, or raises issues, creates PRs, any task really that you can do in GitHub. GitHub manages spinning up a VM to run everything, all you have to do is write your action, and pay (obviously - the best things in life are not always free).&lt;/p>
&lt;p>GitHub actions are defined using YAML inside your repository (in a &lt;code>.github\workflows&lt;/code> folder), and you can call out to &lt;em>actions&lt;/em> that do things, such as checking out code, tagging, running scripts, anything you need. You can also build custom actions.&lt;/p>
&lt;h2 id="custom-actions">Custom actions&lt;/h2>
&lt;p>A custom action is one you write yourself to do whatever you need. In my case, I want my posting code to be run every time I update a markdown file in another repo, and this is something I can do with a custom action.&lt;/p>
&lt;p>Custom actions are either written in JavaScript/TypeScript, or run from a Docker container. My app is Python, so I need to use Docker.&lt;/p>
&lt;h3 id="creating-a-docker-custom-action">Creating a Docker custom action&lt;/h3>
&lt;p>Docker custom actions are Docker containers that can be run, and will stop when they are complete - you package up your app in a container, and provide it with an &lt;code>ENTRYPOINT&lt;/code> so that Docker can run something.&lt;/p>
&lt;p>I created a Dockerfile for my auto post tool, along with a shell script as the entrypoint:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Create this docker file based off a Python 3.9 Linux image&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>FROM python:3.9-slim-buster
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Run everything from /app&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>WORKDIR /app
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Copy over the files&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>COPY requirements.txt requirements.txt
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>COPY app.py app.py
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>COPY dev_to.py dev_to.py
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>COPY github_access.py github_access.py
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>COPY entrypoint.sh entrypoint.sh
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Install the Python requirements&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>RUN pip3 install -r requirements.txt
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Execute the shell script as the entrypoint&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>ENTRYPOINT /app/entrypoint.sh &lt;span style="color:#e6db74">${&lt;/span>@&lt;span style="color:#e6db74">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This Dockerfile creates a container using a Python base image, copies all my files over, installs my Pip package dependencies, then sets the entrypoint.&lt;/p>
&lt;p>The interesting thing to note here is the parameter passed to the &lt;code>entrypoint.sh&lt;/code> script - &lt;code>${0}&lt;/code>. My app needs some secrets passed to it - an API key for Dev.to to allow it to post, the repo to post from, and a GitHub token to allow it to update the repo once the post is up. I don&amp;rsquo;t want these embedded in the container as I want to be able to use this action from different repositories (and allow others to use it), so I want these passed when the action is run. The &lt;code>${0}&lt;/code> syntax means everything that is set as an environment variable when running the container, so this passes all the environment variables to the shell script, where they can be used in the app.&lt;/p>
&lt;p>This means running the container like this:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>docker run ghcr.io/jimbobbennett/auto-blog-poster:main
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> --env DEV_TO_API_KEY&lt;span style="color:#f92672">=&lt;/span>xxx
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> GITHUB_ACCESS_TOKEN&lt;span style="color:#f92672">=&lt;/span>xxx
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> REPO&lt;span style="color:#f92672">=&lt;/span>xxx/yyy
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Will pass &lt;code>DEV_TO_API_KEY=xxx GITHUB_ACCESS_TOKEN=xxx REPO=xxx/yyy&lt;/code> to the shell script, and this can be set as a local environment variable in the container.&lt;/p>
&lt;p>Once created, I can build this container and publish it to the GitHub container registry from an action inside the repo for my post tool.&lt;/p>
&lt;p>This is my action to publish my Docker container:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">Docker Image CI&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">on&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">push&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">branches&lt;/span>: [ &lt;span style="color:#ae81ff">main ]&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">pull_request&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">branches&lt;/span>: [ &lt;span style="color:#ae81ff">main ]&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">env&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">REGISTRY&lt;/span>: &lt;span style="color:#ae81ff">ghcr.io&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">IMAGE_NAME&lt;/span>: &lt;span style="color:#ae81ff">${{ github.repository }}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">jobs&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">build&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">runs-on&lt;/span>: &lt;span style="color:#ae81ff">ubuntu-latest&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">steps&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">Log in to the Container registry&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">uses&lt;/span>: &lt;span style="color:#ae81ff">docker/login-action@f054a8b539a109f9f41c372932f1ae047eff08c9&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">with&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">registry&lt;/span>: &lt;span style="color:#ae81ff">${{ env.REGISTRY }}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">username&lt;/span>: &lt;span style="color:#ae81ff">${{ github.actor }}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">password&lt;/span>: &lt;span style="color:#ae81ff">${{ secrets.GITHUB_TOKEN }}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">uses&lt;/span>: &lt;span style="color:#ae81ff">actions/checkout@v2&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">Extract metadata (tags, labels) for Docker&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">id&lt;/span>: &lt;span style="color:#ae81ff">meta&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">uses&lt;/span>: &lt;span style="color:#ae81ff">docker/metadata-action@98669ae865ea3cffbcbaa878cf57c20bbf1c6c38&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">with&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">images&lt;/span>: &lt;span style="color:#ae81ff">${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">Build and push Docker image&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">uses&lt;/span>: &lt;span style="color:#ae81ff">docker/build-push-action@ad44023a93711e3deb337508980b4b5e9bcdc5dc&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">with&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">context&lt;/span>: &lt;span style="color:#ae81ff">.&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">push&lt;/span>: &lt;span style="color:#66d9ef">true&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">tags&lt;/span>: &lt;span style="color:#ae81ff">${{ steps.meta.outputs.tags }}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">labels&lt;/span>: &lt;span style="color:#ae81ff">${{ steps.meta.outputs.labels }}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This action is run on a push or PR on the main branch. It runs on an Ubuntu VM, logs into the GitHub container registry, checks out my code, gets the tag for the package, builds it and pushed it to the registry.&lt;/p>
&lt;p>This code has some variables that come from GitHub. Any variable that starts &lt;code>${{ github.xxx }}&lt;/code> is set automatically by GitHub to a relevant value such as the repo name. &lt;code>${{ steps.meta.outputs.xxx }}&lt;/code> are set as outputs of certain steps, and &lt;code>${{ secrets.xxx }}&lt;/code> are secrets you can set on your repo. &lt;code>${{ secrets.GITHUB_TOKEN }}&lt;/code> is a special secret you don&amp;rsquo;t need to set that provides an API token to interact with the current repo.&lt;/p>
&lt;p>Once this container is pushed, I can use it from an action inside my blog repo!&lt;/p>
&lt;h3 id="using-a-docker-custom-action">Using a Docker custom action&lt;/h3>
&lt;p>To use a Docker custom action, I can just pull it from inside my blog repo action and run it. Here&amp;rsquo;s the action YAML:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">on&lt;/span>: [&lt;span style="color:#ae81ff">push]&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">env&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">REGISTRY&lt;/span>: &lt;span style="color:#ae81ff">ghcr.io&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">jobs&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">build&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">runs-on&lt;/span>: &lt;span style="color:#ae81ff">ubuntu-latest&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">steps&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">Log in to the Container registry&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">uses&lt;/span>: &lt;span style="color:#ae81ff">docker/login-action@f054a8b539a109f9f41c372932f1ae047eff08c9&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">with&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">registry&lt;/span>: &lt;span style="color:#ae81ff">${{ env.REGISTRY }}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">username&lt;/span>: &lt;span style="color:#ae81ff">${{ github.actor }}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">password&lt;/span>: &lt;span style="color:#ae81ff">${{ secrets.GITHUB_TOKEN }}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">Use Docker CLI&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">uses&lt;/span>: &lt;span style="color:#ae81ff">actions-hub/docker/cli@master&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">env&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">SKIP_LOGIN&lt;/span>: &lt;span style="color:#66d9ef">true&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">run&lt;/span>: &lt;span style="color:#ae81ff">docker pull ghcr.io/jimbobbennett/auto-blog-poster:main&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">run&lt;/span>: &amp;gt;&lt;span style="color:#e6db74">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> docker run ghcr.io/jimbobbennett/auto-blog-poster:main
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> --env DEV_TO_API_KEY=${{ secrets.DEV_TO_API_KEY }}
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> GITHUB_ACCESS_TOKEN=${{ secrets.GITHUB_TOKEN }}
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> REPO=${{ github.repository }}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This action uses a docker custom action to log in to the GitHub container registry, pull my container, then run it, passing in an API key for Dev.to, the GitHub token and the current repository.&lt;/p>
&lt;p>That&amp;rsquo;s it - now every time the blog post markdown changes in my repo, it is automatically deployed to Dev.to.
At the moment this is just a playground, but the plan is to build out a new blog that uses this - all the posts will be in GitHub, and it will post to another blogging platform and Dev.to at every checkin.&lt;/p>
&lt;h2 id="learn-more">Learn more&lt;/h2>
&lt;p>GitHub actions are a lot of fun, and a great way to set up CI/CD. I did a live stream where I worked all this out here:&lt;/p>
&lt;p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/MSfeKTOO1Tc" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;br>
You can also read more on the great &lt;a href="https://docs.github.com/actions">GitHub Actions docs&lt;/a>.&lt;/p></description></item><item><title>Getting started with GitHub Codespaces</title><link>https://jimbobbennett.dev/blogs/github-codespaces/</link><pubDate>Thu, 27 Jan 2022 00:00:00 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/github-codespaces/</guid><description>&lt;p>&lt;img src="banner.png" alt="VS Code running a code space">&lt;/p>
&lt;p>The bane of every new developers life is getting your environment set up to be productive. And when I say new developer - I don&amp;rsquo;t just mean a dev who is new to a team, but every developer who needs to work on a project they haven&amp;rsquo;t worked on before.&lt;/p>
&lt;p>Each project has it&amp;rsquo;s own dependencies, required tools, required libraries, a whole swathe of things that need to be installed, and can in some cases cause problems when projects have conflicting requirements. I certainly remember having to uninstall/reinstall different tooling versions when switching projects, sometimes multiple times a day 😱.&lt;/p>
&lt;p>What if there was a way to fix this? If we could instantly have a pre-configured developer machine with the right tools that we need available at the click of a button? Even better one powered by the cloud so we don&amp;rsquo;t even need to worry about the power of our local machine, or even be able to access from a tablet or phone? This is where &lt;a href="https://github.com/features/codespaces">Codespaces&lt;/a> comes in.&lt;/p>
&lt;p>&lt;a href="https://github.com/features/codespaces">GitHub Codespaces&lt;/a> are virtual developer machines in the cloud that you access through VS Code, running either on your desktop or in a browser. You can launch any GitHub repo inside a Codespace, with everything you do running in that Codespace - your code lives there, your debug sessions run there, your terminal runs commands there, it&amp;rsquo;s as if someone teleported a dev machine into your office!&lt;/p>
&lt;h2 id="setting-up-a-codespace">Setting up a Codespace&lt;/h2>
&lt;p>I&amp;rsquo;ve been recently working on a project for my team that consists of a Python app that I want to run as a Docker container, so I thought it would be fun to configure the repo for this to run inside a Codespace so when anyone else on the team wants to work on it, they won&amp;rsquo;t have any local configuration to do.&lt;/p>
&lt;h3 id="sign-up-for-codespaces">Sign up for Codespaces&lt;/h3>
&lt;p>Codespaces needs to be set up for a team or organization - mainly so someone can pay! Despite the claims that the best things in life are free, you do need to pay for Codespace.&lt;/p>
&lt;h3 id="open-your-repo-in-a-codespace">Open your repo in a Codespace&lt;/h3>
&lt;p>The first step is to open the repo in Codespaces. From the repo in GitHub, select &lt;strong>Codespaces&lt;/strong> from the &lt;strong>Code&lt;/strong> button, then select &lt;strong>New codespace&lt;/strong>.&lt;/p>
&lt;p>&lt;img src="image-2.png" alt="The new codespace button">&lt;/p>
&lt;p>This will set up your code in a new Codespace - essentially a blank VM using a default image from GitHub. This image is based off Ubuntu, and comes pre-configured with Python. Node, Docker and other stuff. You can read up on this default image at &lt;a href="https://aka.ms/ghcs-default-image">aka.ms/ghcs-default-image&lt;/a>.&lt;/p>
&lt;p>This image contains almost everything I need - the tools are all installed, and VS Code is running with my code in it.&lt;/p>
&lt;p>&lt;img src="image-3.png" alt="VS Code running in a browser under Codespaces">&lt;/p>
&lt;p>My code is in Python, and this image comes with Python 3.8 installed. It means I can create a Codespace, and run my code in only a few seconds!&lt;/p>
&lt;h2 id="configure-your-codespace">Configure your Codespace&lt;/h2>
&lt;p>The good news is Codespaces are configurable - you can define the details for the container in which your Codespace runs in a &lt;code>devcontainer.json&lt;/code> file. I can use this to change the image used, configure what tools are installed, that sort of thing. The big upside of this is to ensure I have the right versions - the default container currently has Python 3.8 installed, but I can create a devcontainer file to set another version.&lt;/p>
&lt;p>I&amp;rsquo;ll start by creating a devcontainer file. The Codespaces extension is installed for you in VS Code, so you can use the command palette to access options to configure the devcontainer file.&lt;/p>
&lt;p>I started by selecting &lt;strong>Codespaces: Add Development Container Configuration Files&amp;hellip;.&lt;/strong>&lt;/p>
&lt;p>&lt;img src="image-4.png" alt="The Codespaces: Add Development Container Configuration Files command palette option">&lt;/p>
&lt;p>From there I selected &lt;strong>From a predefined container configuration definition&amp;hellip;&lt;/strong> to use a pre-defined image. I could also use any container I have in my container registry.&lt;/p>
&lt;p>&lt;img src="image-5.png" alt="The From a predefined container configuration definition option">&lt;/p>
&lt;p>From the images I chose a Python 3 image, and selected Python 3.10.&lt;/p>
&lt;p>&lt;img src="image-6.png" alt="The image options with a range of images to choose from">&lt;/p>
&lt;p>&lt;img src="image-9.png" alt="The python 3 version options">&lt;/p>
&lt;p>I then had an option to add a Node version, so selected None as I don&amp;rsquo;t want Node.&lt;/p>
&lt;p>&lt;img src="image-10.png" alt="Node version selection">&lt;/p>
&lt;p>Next I could select features to pre-install. I selected Docker as I need support for that.&lt;/p>
&lt;p>&lt;img src="image-11.png" alt="Selecting the docker option for the container">&lt;/p>
&lt;p>2 things now happen. 2 new files are created in my explorer, &lt;code>devcontainer.json&lt;/code> and &lt;code>Dockerfile&lt;/code> in a folder called &lt;code>.devcontainer&lt;/code>, and a toast will popup suggesting I rebuild the container. When I do this, Codespaces will restart with a new image based off my selections. It takes a while the first time as the container needs to be built.&lt;/p>
&lt;p>&lt;img src="image-12.png" alt="The toast popup">&lt;/p>
&lt;p>The devcontainer.json file directs the Codespace to use the Dockerfile that was created to define the image. It then includes things like a list of extensions that VS Code will need - in my case PyLance.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-json" data-lang="json">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">&amp;#34;extensions&amp;#34;&lt;/span>&lt;span style="color:#960050;background-color:#1e0010">:&lt;/span> [
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;ms-python.python&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;ms-python.vscode-pylance&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>]&lt;span style="color:#960050;background-color:#1e0010">,&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>I could and any more extensions here if I wanted, such as the Docker extension.&lt;/p>
&lt;p>I could also edit these files to create a virtual environment, install Python packages, that sort of thing - though I&amp;rsquo;m not sure I&amp;rsquo;d need a virtual environment as my container will only be used to develop from this repo, so I could install packages globally and not worry.&lt;/p>
&lt;h3 id="check-in-your-files">Check in your files&lt;/h3>
&lt;p>Once you are happy with your dev container setup, you can then check the .devcontainer folder and all it&amp;rsquo;s contents into your repo. This will then be used by anyone who creates a Codespace for your repo!&lt;/p>
&lt;h2 id="learn-more">Learn more&lt;/h2>
&lt;p>If you want to learn more, check out the Codespaces docs - &lt;a href="https://docs.github.com/codespaces">docs.github.com/codespaces&lt;/a>. There was also some great videos on it from GitHub Universe, this particular one by &lt;a href="https://twitter.com/2PercentSilk">Allison Weins&lt;/a> and Bailey Brooks works through the configuration of Codespaces.&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/X9Z-rUixnzk" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div></description></item><item><title>Announcing a New Free Curriculum: IoT for Beginners</title><link>https://jimbobbennett.dev/blogs/announcing-iot-for-beginners/</link><pubDate>Fri, 09 Jul 2021 00:00:00 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/announcing-iot-for-beginners/</guid><description>&lt;p>It is our very great pleasure to announce the release of a new, free, MIT-licensed open-source curriculum all about the Internet of Things: &lt;a href="https://aka.ms/iot-beginners">IoT for Beginners&lt;/a>. Brought to you by a team of Azure Cloud Advocates, Program Managers, and &lt;a href="https://studentambassadors.microsoft.com/">Microsoft Learn Student Ambassadors&lt;/a>, we hope to empower students of all ages to learn the basics of IoT. Presuming no knowledge of IoT, we offer a free 12-week, 24-lesson curriculum to help you dive into this amazing field.&lt;/p>
&lt;p>If you liked our first two curricula, &lt;a href="https://aka.ms/webdev-beginners">Web Dev for Beginners&lt;/a> and &lt;a href="https://aka.ms/ml-beginners">Machine Learning for beginners&lt;/a>, you will love IoT for Beginners!&lt;/p>
&lt;h2 id="join-us-on-the-journey-of-your-food-from-farm-to-table">Join us on the journey of your food, from farm to table!&lt;/h2>
&lt;p>🌽 Join us as we take the same journey as your food as it travels from farm to table, taking advantage of IoT on the way to improve farming, transport, manufacturing and food processing, retail and smart homes. 🌽&lt;/p>
&lt;p>Our curricula are structured with a modified Project-Based pedagogy and include:&lt;/p>
&lt;ul>
&lt;li>a pre-lesson warmup quiz&lt;/li>
&lt;li>a written lesson&lt;/li>
&lt;li>video&lt;/li>
&lt;li>knowledge checks&lt;/li>
&lt;li>a project to build&lt;/li>
&lt;li>infographics, sketchnotes, and visuals&lt;/li>
&lt;li>a challenge&lt;/li>
&lt;li>an assignment&lt;/li>
&lt;li>a post-lesson quiz&lt;/li>
&lt;li>opportunities to deepen your knowledge on Microsoft Learn&lt;/li>
&lt;/ul>
&lt;h2 id="what-will-you-learn">What will you learn?&lt;/h2>
&lt;p>&lt;img src="Roadmap.jpg" alt="The curriculum roadmap">&lt;/p>
&lt;p>The lessons are grouped so that you can deep-dive into use cases of IoT. We start with an introduction to IoT, covering devices, sensors, actuators and cloud connectivity, where you will build an internet connected version of the &amp;ldquo;Hello world&amp;rdquo; or IoT, an LED. We then move on to farming, learning about digital agriculture and feedback loops to control automated watering systems. Your food then leaves the farm on trucks, and you learn how to track vehicles using GPS, visualize their journeys and get alerts when a truck approaches a processing plant. Once in the plant, we move to AIoT, learning how to distinguish between ripe and unripe fruit using AI models running from IoT devices and on the edge. Next we move to the supermarket, using IoT to manage stock levels. Finally we take the food home to cook, and learn about consumer smart devices, building a voice controlled smart timer that can even speak multiple languages.&lt;/p>
&lt;h2 id="hardware">Hardware&lt;/h2>
&lt;p>The hard part (pun intended) for IoT is hardware, so we&amp;rsquo;ve designed this curriculum to be as accessible as possible. We want you to Learn IoT, not learn how to solder, know how to read resistor color codes, or know what a microfarad is, so we&amp;rsquo;ve made hardware choices to make things easier.&lt;/p>
&lt;p>You can choose to learn using microcontrollers using Arduino with a &lt;a href="https://www.seeedstudio.com/Wio-Terminal-p-4509.html">Wio Terminal&lt;/a>, or single board computers using a &lt;a href="https://www.raspberrypi.org/products/raspberry-pi-4-model-b/">Raspberry Pi&lt;/a>. We&amp;rsquo;ve also added a &lt;a href="https://github.com/CounterFit-IoT">virtual hardware option&lt;/a> so you can learn without having to purchase anything!&lt;/p>
&lt;p>For sensors and actuators, we&amp;rsquo;ve gone with the &lt;a href="https://www.seeedstudio.com/category/Grove-c-1003.html">Grove kit&lt;/a> from &lt;a href="https://www.seeedstudio.com/">Seeed Studio&lt;/a>, with easy to connect sensors and actuators.&lt;/p>
&lt;p>&lt;img src="seeed.png" alt="The Seeed studio logo">&lt;/p>
&lt;p>Our friends at Seeed have made it easy to buy the hardware, with packages containing all of the kit you need.&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://www.seeedstudio.com/IoT-for-beginners-with-Seeed-and-Microsoft-Wio-Terminal-Starter-Kit-p-5006.html">IoT for beginners with Seeed and Microsoft - Wio Terminal Starter Kit&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.seeedstudio.com/IoT-for-beginners-with-Seeed-and-Microsoft-Raspberry-Pi-Starter-Kit.html">IoT for beginners with Seeed and Microsoft - Raspberry Pi 4 Starter Kit&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>If you are interested in learning using virtual hardware, you can write IoT code locally as if you were using a Raspberry Pi, then simulate sensors and actuators using &lt;a href="https://github.com/CounterFit-IoT">CounterFit&lt;/a>, a free, open source tool for simulating hardware.&lt;/p>
&lt;h2 id="a-sneak-peek">A sneak peek&lt;/h2>
&lt;p>This curriculum is filled with a lot of art, created by our team. Take a look at this cool sketchnote created by &lt;a href="https://twitter.com/nitya">@nitya&lt;/a>.&lt;/p>
&lt;p>&lt;img src="sketchnote.png" alt="A sketch note visualizing lesson 1 of the curriculum">&lt;/p>
&lt;p>Without further ado, please meet &lt;a href="https://aka.ms/iot-beginners">IoT For Beginners: A Curriculum&lt;/a>!&lt;/p></description></item><item><title>Using TinyML to identify farts</title><link>https://jimbobbennett.dev/blogs/tiny-ml-farts/</link><pubDate>Mon, 22 Feb 2021 17:01:05 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/tiny-ml-farts/</guid><description>&lt;blockquote>
&lt;p>TLDR; Find a complete hands-on lab to build a TinyML audio classifier at &lt;a href="https://github.com/microsoft/iot-curriculum/tree/main/labs/tiny-ml/audio-classifier">github.com/microsoft/iot-curriculum/tree/main/labs/tiny-ml/audio-classifier&lt;/a>.&lt;/p>
&lt;/blockquote>
&lt;p>My 8-year-old daughter bought me &amp;ldquo;Farts - a spotters guide&amp;rdquo; - a book with some buttons down the side and when you press them, they make different fart sounds. This is the height of humor for an 8 year old, and still pretty funny as an adult. I thought it would be fun to see if I could distinguish between the different fart noises using machine learning - and not just any machine learning, but seeing as I love IoT, I wanted it to run on a microcontroller!&lt;/p>
&lt;p>&lt;img src="fart-book.jpg" alt="Farts, a spotters guide">&lt;/p>
&lt;h2 id="tinyml">TinyML&lt;/h2>
&lt;p>TinyML is a relatively new field, and is all about creating tiny machine learning models that can run on microcontrollers. These models are really tiny - in the order of kilobytes instead of the usual megabytes or gigabytes. They need to be this tiny to run on microcontrollers that typically have kilobytes of RAM. These models also draw little power, typically in the single-digit milliwatts or lower.&lt;/p>
&lt;p>What are the use cases for TinyML? Well there are loads, anywhere you want to run ML models offline with minimal power draw. You may even have some TinyML models running in your house right now. For example, smart voice controlled devices listen for a wake word, and this needs to be offline and draw minimal power - perfect for a TinyML model. Another use case is in healthcare with devices that can monitor your health that run for years on tiny batteries. It&amp;rsquo;s also being used in animal smart collars and trackers, &lt;a href="https://www.hackster.io/contests/ElephantEdge">using audio to monitor the health of elephants in the wild&lt;/a>. So yes - a fart detector has a real world application!&lt;/p>
&lt;p>To build a TinyML model you need to decide what type of model to build, gather training data, train the model, then deploy it to your device to handle new data. In this case, I wanted an audio classifier, so decided to use a &lt;a href="https://scikit-learn.org/stable/modules/svm.html">support vector machine classifier&lt;/a>.&lt;/p>
&lt;blockquote>
&lt;p>Despite this sounding all fancy and like I know what I&amp;rsquo;m talking about, I actually have no clue what this is - I just learned about them from a great tutorial which I followed to get inspiration for this post! The tutorial is &lt;a href="https://eloquentarduino.github.io/2020/08/better-word-classification-with-arduino-33-ble-sense-and-machine-learning/">Better word classification with Arduino Nano 33 BLE Sense and Machine Learning&lt;/a>.&lt;/p>
&lt;/blockquote>
&lt;h2 id="building-a-fart-detector">Building a fart detector&lt;/h2>
&lt;p>For my fart detector, I needed to build an audio classifier that could run on a microcontroller. Because I&amp;rsquo;m terrible at electronics and understanding I2C, SPI and all that other stuff, I decided to use an all-in-one Arduino board that has a microphone built in allowing me to use off-the-shelf Arduino libraries to gather audio data. The board of choice was the Arduino Nano 33 Sense BLE board, a small Arduino board with a whole raft of sensors including a microphone, temperature, pressure, humidity, light level and color, gesture and proximity. That&amp;rsquo;s a lot of sensors in such a tiny board!&lt;/p>
&lt;p>&lt;img src="nano-sense.jpg" alt="An arduino Nano sense 33 BLE IoT board">&lt;/p>
&lt;p>To code this board, I could use the free Arduino IDE, but I prefer to use &lt;a href="https://code.visualstudio.com/">Visual Studio Code&lt;/a>, along with the &lt;a href="https://platformio.org/">PlatformIO extension&lt;/a>. This allows the creation of standalone microcontroller projects with .ini files that define the board and libraries used. I can check a project into GitHub and someone can clone it and immediately start working with it without the need for instructions on what boards and libraries they need to set up.&lt;/p>
&lt;h3 id="getting-training-data">Getting training data&lt;/h3>
&lt;p>To train TinyML models you not only need the model to by tiny, but you also need small inputs - the more data that goes into training the model or inference (that is running the model), the larger it is. Audio data can be quite large - for example CD quality audio (remember CDs?) is 44.1KHz/16-bit which means it captures 2 bytes of data 44,100 times per second, or 176KB per second! That&amp;rsquo;s a lot of data - if we wanted to use all of it and train our model with 2 seconds worth of data it wouldn&amp;rsquo;t be TinyML any more.&lt;/p>
&lt;p>A great trick with audio data is realizing you don&amp;rsquo;t need all of it to classify particular sounds. Instead you can get an average value that represents many samples and use that as the data. In the case of the Arduino, the library that captures audio, &lt;a href="https://www.arduino.cc/en/Reference/PDM">PDM&lt;/a>, captures audio at 16KHz in 512 byte buffers, containing 256 2-byte samples. This means each buffer has 1/64th of a second of audio data in it. We can then calculate a root mean square (RMS) of all this data to get a single 4-byte floating point value. If we do this for every buffer, we end up with 64 4-byte floats per second, or 256 bytes per second. Much smaller than raw audio at the PDM sample rate of 16KHz giving 32,000 bytes per second!&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cpp" data-lang="cpp">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">#define BUFFER_SIZE 512U
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span>...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">// Check we have a full buffers worth
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#66d9ef">if&lt;/span> (PDM.available() &lt;span style="color:#f92672">==&lt;/span> BUFFER_SIZE)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">// Read from the buffer
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> PDM.read(_buffer, BUFFER_SIZE);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">// Calculate the root mean square value of the buffer
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">int16_t&lt;/span> rms;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> arm_rms_q15((q15_t &lt;span style="color:#f92672">*&lt;/span>)_buffer, BUFFER_SIZE&lt;span style="color:#f92672">/&lt;/span>&lt;span style="color:#66d9ef">sizeof&lt;/span>(&lt;span style="color:#66d9ef">int16_t&lt;/span>), (q15_t &lt;span style="color:#f92672">*&lt;/span>)&lt;span style="color:#f92672">&amp;amp;&lt;/span>rms);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The RMS value can be checked against a threshold to see if there is actual audio data or not, and if audio data is detected, the next 2 seconds worth can be grabbed. In this case it&amp;rsquo;s output to the serial port so it can be read from the PlatformIO serial monitor in VS Code.&lt;/p>
&lt;p>You can find the full code to capture audio samples in the &lt;a href="https://github.com/microsoft/iot-curriculum/tree/main/labs/tiny-ml/audio-classifier/code/audio-capture">Microsoft IoT Curriculum resource GitHub repo in the labs folder&lt;/a>.&lt;/p>
&lt;h3 id="train-the-model">Train the model&lt;/h3>
&lt;p>To train the model, we need a good range of audio data captured from the Arduino device - ideally 15-30 samples per audio we want to classify. A classifier distinguishes the input between multiple labels, so we need to gather data for multiple labels. For example, to classify the farts from my fart book I&amp;rsquo;d need to gather 15-30 samples for at least 2 different farts.&lt;/p>
&lt;p>The audio data sent to the serial monitor from the Arduino can be captured into .csv files, and these can be loaded by a Python script and used to train a model.&lt;/p>
&lt;p>The model in question is trained using &lt;a href="https://scikit-learn.org/">Scikit-Learn&lt;/a>, a Python Machine Learning library. The audio data is loaded into numpy arrays, then split into training and testing data, the model is trained using the training data, then tested with the testing data to give an idea on the accuracy.&lt;/p>
&lt;blockquote>
&lt;p>If you have a nice shiny Apple M1 mac (like I do), then installing Scikit-Learn is currently not as easy. Check out my &lt;a href="https://jimbobbennett.dev/blogs/installing-scikit-learn-on-an-apple-m1/">guide on how to install it&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cpp" data-lang="cpp">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Split the data into a training and testing set to test the accuracy of the model
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># If you are happy with the accuracy of the model, you can remove this split
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span>dataset_train, dataset_test, label_train, label_test &lt;span style="color:#f92672">=&lt;/span> train_test_split(dataset, dataset_labels.ravel(), test_size&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">0.2&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Build the support vector classification for our data and train the model
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span>svc &lt;span style="color:#f92672">=&lt;/span> SVC(kernel&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#960050;background-color:#1e0010">&amp;#39;&lt;/span>poly&lt;span style="color:#960050;background-color:#1e0010">&amp;#39;&lt;/span>, degree&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">2&lt;/span>, gamma&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">0.1&lt;/span>, C&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">100&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>svc.fit(dataset_train, label_train)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Test the accuracy of the model
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span>print(&lt;span style="color:#960050;background-color:#1e0010">&amp;#39;&lt;/span>Accuracy:&lt;span style="color:#960050;background-color:#1e0010">&amp;#39;&lt;/span>, svc.score(dataset_test, label_test))
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Once the model has been trained, it can be exported using the rather useful &lt;a href="https://pypi.org/project/micromlgen/">micromlgen Python library&lt;/a> which can convert ML models into raw C++ code to run on microcontrollers.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cpp" data-lang="cpp">&lt;span style="display:flex;">&lt;span>from micromlgen import port
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Convert the model to C code and write to the classifier.h file
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span>c_code &lt;span style="color:#f92672">=&lt;/span> port(svc, classmap&lt;span style="color:#f92672">=&lt;/span>label_map)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>with open(&lt;span style="color:#960050;background-color:#1e0010">&amp;#39;&lt;/span>classifier.h&lt;span style="color:#960050;background-color:#1e0010">&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;w&amp;#39;&lt;/span>) as f:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> f.write(c_code)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> f.close()
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>You can find the training code in the &lt;a href="https://github.com/microsoft/iot-curriculum/tree/main/labs/tiny-ml/audio-classifier/code/model-trainer">Microsoft IoT Curriculum resource GitHub repo in the labs folder&lt;/a>.&lt;/p>
&lt;h2 id="classify-farts">Classify farts&lt;/h2>
&lt;p>The C++ code that comes out of the training can then be added to the microcontroller code. Instead of dumping the audio data to the serial port, it can be sent to the classifier code, and the label of the best match is returned.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cpp" data-lang="cpp">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">void&lt;/span> &lt;span style="color:#a6e22e">processSamples&lt;/span>()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">// Write out the classification to the serial port
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> Serial.print(&lt;span style="color:#e6db74">&amp;#34;Label: &amp;#34;&lt;/span>);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Serial.println(clf.predictLabel(_samples));
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="learn-more">Learn more&lt;/h2>
&lt;p>You can find a complete hands on lab implementing this in the &lt;a href="https://github.com/microsoft/iot-curriculum/tree/main/labs/tiny-ml/audio-classifier">Microsoft IoT Curriculum resource GitHub repo in the labs folder&lt;/a>.&lt;/p></description></item><item><title>Installing Scikit-Learn on a Apple Silicon</title><link>https://jimbobbennett.dev/blogs/installing-scikit-learn-on-an-apple-m1/</link><pubDate>Sun, 31 Jan 2021 17:01:05 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/installing-scikit-learn-on-an-apple-m1/</guid><description>&lt;p>At the end of last year I splashed out on a shiny new Apple MacBookAir with the M1 processor as I was fed up with an old Intel-based MacBookPro that was quite honestly crippled by corporate anti-virus software.&lt;/p>
&lt;p>Out the box this machine is amazing. It&amp;rsquo;s ridiculously fast, and lasts for ever on battery. Seriously - I charge it every 2 days and manage a full day of coding, writing, emails, Teams, the lot. Did I also mention it&amp;rsquo;s fast? I can have all the things running and it barely breaks a sweat, even with only 8GB of RAM.&lt;/p>
&lt;p>The downside is that not all software works on the new ARM-64 architecture. Apple have a translation layer called Rosetta 2 (Rosetta 1 was their translation from PowerPC to Intel), and this works great most of the time for every day apps, but it doesn&amp;rsquo;t always work for development tools and libraries, as the mix of translated and untranslated stuff just breaks down.&lt;/p>
&lt;p>One library I needed to use that isn&amp;rsquo;t supported is Scikit-Learn. Now I&amp;rsquo;m no Python expert, and I don&amp;rsquo;t really understand what Scikit-Learn does, I just know I need it to train some TinyML models to &lt;a href="https://eloquentarduino.github.io/2020/08/better-word-classification-with-arduino-33-ble-sense-and-machine-learning/">recognize wake words on an Arduino Nano 33 sense board&lt;/a>. If I try a normal pip install scikit-learn, I get a whole wall of errors, both using Python 3.9 for the M1, and Python 3.8 under Rosetta.&lt;/p>
&lt;p>So what to do?&lt;/p>
&lt;p>It turns out the solution is to use &lt;a href="https://github.com/conda-forge/miniforge">Miniforge&lt;/a>, a version of Conda that is comparable to Miniconda, but supports various CPU architectures. Whatever that means. As I said, I&amp;rsquo;m no Python expert, but this tool essentially allows me to create virtual environments and install packages compiling them for the M1 chip! Any packages it doesn&amp;rsquo;t support can then be installed from pip.&lt;/p>
&lt;p>So how do I install all this?&lt;/p>
&lt;p>Firstly - I need to install Miniforge. The install script is on the GitHub page, or you can download it by clicking &lt;a href="https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-MacOSX-arm64.sh">this link&lt;/a>. It wanted to activate it in every terminal, which I didn&amp;rsquo;t want so I turned that off by running:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>conda config --set auto_activate_base false
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Next I went to the folder containing my Python code, and created a virtual environment:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>conda create -n .venv python
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This is pretty much the same as creating a virtual environment with Python, just using a different tool. Like with Python, the virtual environment then needs to be activated:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>conda activate .venv
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Finally, I can install Scikit-Learn:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>conda install scikit-learn
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Done! For the particular thing I&amp;rsquo;m working on, I needed a package that isn&amp;rsquo;t available from Miniforge, so I just installed it with pip:&lt;/p>
&lt;p>pip install micromlgen
Done! I could then run my Python script as normal, and it all worked nicely. And fast - my M1 ran the script in question in 2 seconds, 5 times faster than the 10 seconds my Surface Book took.&lt;/p></description></item></channel></rss>